{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "167e745a-84a4-4771-b2b6-e3662c6c2227",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import  SparkSession\n",
    "import requests\n",
    "from pyspark.sql.types import StructType,StructField,StringType,IntegerType,DateType,DoubleType\n",
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "\n",
    "api_url = \"https://script.google.com/macros/s/AKfycbx7A9tr8uHmTNGYv5Q2O24cthTYUzZPd1uqaFvHsBNShDmduvYZazpvgy3bY3-agt5e0g/exec\"\n",
    "\n",
    "response = requests.get(url=api_url)\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "\n",
    "else:\n",
    "    print(\"API request failed with status code: \",response.status_code)\n",
    "\n",
    "data=[i[0].split(\",\") for i in result['rows']]\n",
    "data = [[int(row[0]), *row[1:]] for row in data]\n",
    "\n",
    "\n",
    "schema=StructType([\n",
    "    StructField('product_id',IntegerType(),True),\n",
    "    StructField('customer_id',StringType(),True),\n",
    "    StructField('order_date',StringType(),True),\n",
    "    StructField('location',StringType(),True),\n",
    "    StructField('source_order',StringType(),True)\n",
    "\n",
    "])\n",
    "\n",
    "df_api = spark.createDataFrame(data,schema=schema)\n",
    "df_api=df_api.withColumn('order_date',to_date(df_api['order_date'],'yyyy-MM-dd'))\n",
    "\n",
    "schema=StructType([\n",
    "    StructField('product_id',IntegerType(),True),\n",
    "    StructField('customer_id',StringType(),True),\n",
    "    StructField('order_date',DateType(),True),\n",
    "    StructField('location',StringType(),True),\n",
    "    StructField('source_order',StringType(),True)\n",
    "\n",
    "])\n",
    "df_file= spark.read.csv(\"/FileStore/tables/sales_csv.txt\",schema=schema)\n",
    "\n",
    "schema_menu=StructType([\n",
    "    StructField('product_id',IntegerType(),True),\n",
    "    StructField('product_name',StringType(),True),\n",
    "    StructField('price',DoubleType(),True)\n",
    "])\n",
    "df_menu=spark.read.csv(\"/FileStore/tables/menu_csv.txt\",\n",
    "                       schema=schema_menu)\n",
    "\n",
    "df=df_api.union(df_file)\n",
    "\n",
    "# Transformation\n",
    "from pyspark.sql.functions import month, year, quarter\n",
    "df=df.withColumn('order_year',year('order_date'))\n",
    "df=df.withColumn('order_quarter',quarter('order_date'))\n",
    "df=df.withColumn('order_month',month('order_date'))\n",
    "\n",
    "df_final=df.join(df_menu,on='product_id',how='inner')\n",
    "\n",
    "#load\n",
    "output_path='/FileStore/tables/output'\n",
    "df_final.coalesce(1).write.mode(\"overwrite\").parquet(output_path)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Restaurant_1_ETL",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
